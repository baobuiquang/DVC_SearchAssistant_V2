{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from underthesea import word_tokenize\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as Selenium_Service\n",
    "from selenium.webdriver.chrome.options import Options as Selenium_Options\n",
    "from selenium.webdriver import Chrome as Selenium_Chrome\n",
    "chrome_options = Selenium_Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "selenium_service = Selenium_Service(ChromeDriverManager().install())\n",
    "selenium_driver = Selenium_Chrome(service=selenium_service, options=chrome_options) # Start WebDriver\n",
    "# sele_driver.quit() # Close the browser\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.replace('đ', 'd').replace('Đ', 'D')\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "    text = text.lower().strip()\n",
    "    return text\n",
    "def extract_keywords(text):\n",
    "    def is_number(text):\n",
    "        return bool(re.fullmatch(r'[\\d,. ]+', text))\n",
    "    specialchars = ['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '..', '...', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n",
    "    specialwords = [\"giấy tờ\", \"thủ tục\", \"giấy\", \"gì\", \"cần\", \"nào\", \"sắp\", \"đang\", \"sẽ\", \"của\", \"bị\", \"hoặc\", \"với\", \"và\", \"thì\", \"muốn\", \"gì\", \"mình\", \"tôi\", \"phải\", \"làm sao\", \"để\", \"cho\", \"làm\", \"như\", \"đối với\", \"từ\", \"theo\", \"là\", \"được\", \"ở\", \"đã\", \"về\", \"có\", \"các\", \"tại\", \"đến\", \"vào\", \"do\", \"vì\", \"bởi vì\", \"thuộc\"]\n",
    "    words = word_tokenize(text)\n",
    "    words = [w.lower().strip() for w in words]\n",
    "    words = list(set(words))\n",
    "    words = [w for w in words if not is_number(w)]\n",
    "    words = [w for w in words if w not in specialchars]\n",
    "    words = [w for w in words if w not in specialwords]\n",
    "    words_normalized = [normalize_text(w) for w in words if \" \" in w]\n",
    "    return list(set(words + words_normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ---------- [Optional] Re-raw2cache ----------\n",
    "# def raw2cache(raw_path, cache_path):\n",
    "#     # Step 1\n",
    "#     with open(raw_path, 'r', encoding='utf-8') as f1:\n",
    "#         lines = f1.readlines()\n",
    "#         lines = [line.strip() for line in lines if line.strip()]\n",
    "#         items = [lines[i:i+6] for i in range(0, len(lines), 6)]\n",
    "#         headers = [\"STT\", \"Mã chuẩn\", \"Tên thủ tục\", \"Lĩnh vực\", \"Cơ quan thực hiện\", \"Mức độ\"]\n",
    "#         with open(cache_path, 'w', newline='', encoding='utf-8') as f2:\n",
    "#             writer = csv.writer(f2)\n",
    "#             writer.writerow(headers)\n",
    "#             writer.writerows(items)\n",
    "#     # Step 2\n",
    "#     with open(cache_path, mode='r', newline='', encoding='utf-8') as f:\n",
    "#         thutucs = list(csv.DictReader(f))\n",
    "#         thutucs = sorted(thutucs, key=lambda e: len(e[\"Tên thủ tục\"]))\n",
    "#         for e in thutucs:\n",
    "#             e[\"thutuc_Link\"] = \"NOINFO\"\n",
    "#             e[\"thutuc_Trình tự thực hiện\"] = \"NOINFO\"\n",
    "#             e[\"thutuc_Cách thức thực hiện\"] = \"NOINFO\"\n",
    "#             e[\"thutuc_Thành phần hồ sơ\"] = \"NOINFO\"\n",
    "#             e[\"thutuc_Thời gian giải quyết\"] = \"NOINFO\"\n",
    "#             e[\"thutuc_Đối tượng thực hiện\"] = \"NOINFO\"\n",
    "#             e[\"thutuc_Cơ quan thực hiện\"] = \"NOINFO\"\n",
    "#             e[\"thutuc_Kết quả\"] = \"NOINFO\"\n",
    "#             e[\"thutuc_Phí, lệ phí\"] = \"NOINFO\"\n",
    "#             e[\"thutuc_Tên mẫu đơn, tờ khai\"] = \"NOINFO\"\n",
    "#             e[\"thutuc_Yêu cầu, điều kiện\"] = \"NOINFO\"\n",
    "#             e[\"thutuc_Căn cứ pháp lý\"] = \"NOINFO\"\n",
    "#     with open(cache_path, mode='w', newline='', encoding='utf-8') as f:\n",
    "#         fieldnames = thutucs[0].keys()\n",
    "#         writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "#         writer.writeheader()\n",
    "#         writer.writerows(thutucs)\n",
    "# raw2cache(\"url/raw\", \"url/cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Load thutucs from cache ----------\n",
    "with open('url/cache', mode='r', newline='', encoding='utf-8') as f:\n",
    "    thutucs = list(csv.DictReader(f))\n",
    "    for i in range(len(thutucs)):\n",
    "        thutucs[i][\"keywords\"] = extract_keywords(thutucs[i][\"Tên thủ tục\"])\n",
    "    tenthutucs = [e[\"Tên thủ tục\"] for e in thutucs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_e5 = SentenceTransformer(\"onelevelstudio/M-E5-BASE\")\n",
    "model_mpnet = SentenceTransformer(\"onelevelstudio/M-MPNET-BASE\")\n",
    "\n",
    "# # ---------- [Optional] Re-vectorize embeddings ----------\n",
    "# embs_e5    = model_e5.encode(tenthutucs)\n",
    "# np.save(\"url/embs_e5\", embs_e5)\n",
    "# os.rename(\"url/embs_e5.npy\", \"url/embs_e5\")\n",
    "# embs_mpnet = model_mpnet.encode(tenthutucs)\n",
    "# np.save(\"url/embs_mpnet\", embs_mpnet)\n",
    "# os.rename(\"url/embs_mpnet.npy\", \"url/embs_mpnet\")\n",
    "\n",
    "# ---------- Load pre-vectorized embeddings ----------\n",
    "embs_e5 = np.load(\"url/embs_e5\")\n",
    "embs_mpnet = np.load(\"url/embs_mpnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Process 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- [Optional] Re-scrape content ----------\n",
    "\n",
    "patterns = {\n",
    "    \"Trình tự thực hiện\": r\"\"\">Trình tự thực hiện</td>\\s*<td[^>]*>(.*?)</td>\"\"\", \n",
    "    \"Cách thức thực hiện\": r\"\"\">Cách thức thực hiện</td>\\s*<td[^>]*>(.*?)</td>\"\"\", \n",
    "    \"Thành phần hồ sơ\": r\"\"\">Thành phần hồ sơ</td>\\s*<td[^>]*>(.*?)</td>\"\"\", \n",
    "    \"Thời gian giải quyết\": r\"\"\">Thời gian giải quyết</td>\\s*<td[^>]*>(.*?)</td>\"\"\", \n",
    "    \"Đối tượng thực hiện\": r\"\"\">Đối tượng thực hiện</td>\\s*<td[^>]*>(.*?)</td>\"\"\", \n",
    "    \"Cơ quan thực hiện\": r\"\"\">Cơ quan thực hiện</td>\\s*<td[^>]*>(.*?)</td>\"\"\", \n",
    "    \"Kết quả\": r\"\"\">Kết quả</td>\\s*<td[^>]*>(.*?)</td>\"\"\", \n",
    "    \"Phí, lệ phí\": r\"\"\">Phí, lệ phí</td>\\s*<td[^>]*>(.*?)</td>\"\"\", \n",
    "    \"Tên mẫu đơn, tờ khai\": r\"\"\">Tên mẫu đơn, tờ khai</td>\\s*<td[^>]*>(.*?)</td>\"\"\", \n",
    "    \"Yêu cầu, điều kiện\": r\"\"\">Yêu cầu, điều kiện</td>\\s*<td[^>]*>(.*?)</td>\"\"\", \n",
    "    \"Căn cứ pháp lý\": r\"\"\">Căn cứ pháp lý</td>\\s*<td[^>]*>(.*?)</td>\"\"\", \n",
    "}\n",
    "\n",
    "def get_thutuc_content_from_machuan(machuan):\n",
    "\n",
    "    final_res = {}\n",
    "\n",
    "    def scrape_html_content(url, waiting_time=2):\n",
    "        selenium_driver.get(url)\n",
    "        time.sleep(waiting_time)\n",
    "        html_content = selenium_driver.page_source\n",
    "        return html_content\n",
    "\n",
    "    try:\n",
    "        url_search = \"https://dichvucong.lamdong.gov.vn/vi/procedure/search?keyword=\" + machuan\n",
    "        search_html_content = scrape_html_content(url_search)\n",
    "        match = re.search(r'href=\"(/vi/procedure/detail/[a-zA-Z0-9]+)\"', search_html_content)\n",
    "        if match:\n",
    "            url_thutuc_content = \"https://dichvucong.lamdong.gov.vn\" + match.group(1)\n",
    "            final_res[\"thutuc_Link\"] = url_thutuc_content\n",
    "            # ----------------------------------------------------------------------------------------------------\n",
    "            thutuc_html_content = scrape_html_content(url_thutuc_content)\n",
    "            for i in range(len(patterns)):\n",
    "                pattern_name = list(patterns.keys())[i]\n",
    "                pattern_regex = list(patterns.values())[i]\n",
    "                match = re.search(pattern_regex, thutuc_html_content, re.DOTALL)\n",
    "                if match:\n",
    "                    extracted_text = match.group(1)\n",
    "                    extracted_text = re.sub(r'</?[^>]+>', '\\n', extracted_text) # Replace HTML tags with \"\\n\"\n",
    "                    extracted_text = re.sub(r'\\n+', '\\n', extracted_text)       # Merge multiple \"\\n\"\n",
    "                    extracted_text = extracted_text.replace(\"&nbsp;\", \" \")      # Replace &nbsp; with \" \"\n",
    "                    extracted_text = extracted_text.strip()\n",
    "                    extracted_text = extracted_text if extracted_text != \"\" else f\"Không có thông tin {pattern_name.lower()}.\"\n",
    "                    final_res[f\"thutuc_{pattern_name}\"] = f\"{extracted_text}\"\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ > Error: {e}\")\n",
    "    return final_res\n",
    "\n",
    "with open('url/cache', mode='r', newline='', encoding='utf-8') as f:\n",
    "    thutucs_crawl = list(csv.DictReader(f))\n",
    "with open('url_backup/cache', mode='r', newline='', encoding='utf-8') as f:\n",
    "    thutucs_crawl_backup = list(csv.DictReader(f))\n",
    "\n",
    "for i in range(len(thutucs_crawl)):\n",
    "    machuan = thutucs_crawl[i][\"Mã chuẩn\"]\n",
    "    if thutucs_crawl[i][\"thutuc_Link\"] == \"NOINFO\":\n",
    "        \n",
    "        # ----------\n",
    "        thutuc_content = {}\n",
    "        for ee in thutucs_crawl_backup:\n",
    "            if machuan == ee[\"Mã chuẩn\"]:\n",
    "                thutuc_content[f\"thutuc_Link\"] = ee[f\"thutuc_Link\"]\n",
    "                for pattern_name in list(patterns.keys()):\n",
    "                    thutuc_content[f\"thutuc_{pattern_name}\"] = ee[f\"thutuc_{pattern_name}\"]\n",
    "                break\n",
    "        if len(thutuc_content) != len(patterns)+1:\n",
    "            thutuc_content = get_thutuc_content_from_machuan(machuan)\n",
    "            time.sleep(2)\n",
    "        # ----------\n",
    "\n",
    "        if len(thutuc_content) == len(patterns)+1:\n",
    "            print(\"✔️\", end=\"\")\n",
    "            # ----------\n",
    "            thutucs_crawl[i][f\"thutuc_Link\"] = thutuc_content[f\"thutuc_Link\"]\n",
    "            for pattern_name in list(patterns.keys()):\n",
    "                thutucs_crawl[i][f\"thutuc_{pattern_name}\"] = thutuc_content[f\"thutuc_{pattern_name}\"]\n",
    "            # ----------\n",
    "            with open(\"url/cache\", mode='w', newline='', encoding='utf-8') as f:\n",
    "                fieldnames = thutucs_crawl[0].keys()\n",
    "                writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "                writer.writeheader()\n",
    "                writer.writerows(thutucs_crawl)\n",
    "        else:\n",
    "            print(\"❌\", end=\"\")\n",
    "    else:\n",
    "        print(\"⏩\", end=\"\")\n",
    "    if i % 50 == 49:\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = [\n",
    "\"mình sắp khởi nghiệp cần giấy tờ gì?\",\n",
    "\"tôi muốn mua đất thì cần làm gì?\",\n",
    "\"tôi sắp cưới vợ thì phải làm như nào?\",\n",
    "\"tôi sắp lập gia đình thì cần làm gì?\",\n",
    "\"vợ tôi sắp sinh con thủ tục nào?\",\n",
    "\"thủ tục xây nhà cấp 3 cấp 4?\",\n",
    "\"làm sao để phúc khảo bài thi thpt?\",\n",
    "\"làm sao để tố cáo hành vi vi phạm pháp luật?\",\n",
    "\"tôi muốn ly dị chồng, tôi phải làm gì?\",\n",
    "\"tôi muốn ly hôn chồng, tôi phải làm gì?\",\n",
    "\"tôi muốn chuyển hộ khẩu cho con của tôi\",\n",
    "\"làm sao để đăng ký nhập học cho con của tôi?\",\n",
    "\"dang ky ket hon\",\n",
    "\"đăng ký kết hôn\",\n",
    "\"đăng ký\",\n",
    "\"tố cáo xã\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_idx_exactmatch(text, thutucs, top=5):\n",
    "    thutuc_scores = []\n",
    "    for e in thutucs:\n",
    "        score = 0\n",
    "        # ----------\n",
    "        if normalize_text(text) in normalize_text(e[\"Tên thủ tục\"]):\n",
    "            score += 1\n",
    "            if text.lower() in e[\"Tên thủ tục\"].lower():\n",
    "                score += 1\n",
    "        # ----------\n",
    "        thutuc_scores.append(score)\n",
    "    thutuc_scores_idx = sorted(range(len(thutuc_scores)), key=lambda i: thutuc_scores[i], reverse=True)\n",
    "    scores = [(idx, thutuc_scores[idx]) for idx in thutuc_scores_idx]\n",
    "    scores = [e for e in scores if e[1] != 0]\n",
    "    return [e[0] for e in scores][:min(len(scores), top)]\n",
    "\n",
    "def retrieve_idx_keywordmatch(text, thutucs, top=5):\n",
    "    q_keywords = extract_keywords(text)\n",
    "    # print(q_keywords)\n",
    "    thutuc_scores = []\n",
    "    for e in thutucs:\n",
    "        score = 0\n",
    "        # ----------\n",
    "        for k in q_keywords:\n",
    "            if k in e[\"keywords\"]:\n",
    "                score += 1\n",
    "        # ----------\n",
    "        thutuc_scores.append(score)\n",
    "    thutuc_scores_idx = sorted(range(len(thutuc_scores)), key=lambda i: thutuc_scores[i], reverse=True)\n",
    "    scores = [(idx, thutuc_scores[idx]) for idx in thutuc_scores_idx]\n",
    "    scores = [e for e in scores if e[1] != 0]\n",
    "    return [e[0] for e in scores][:min(len(scores), top)]\n",
    "\n",
    "def retrieve_idx_semantic(text, pre_embs, emb_model, top=5):\n",
    "    q_emb = emb_model.encode(text)\n",
    "    similarities = emb_model.similarity(q_emb, pre_embs)[0]\n",
    "    top_5_idx = sorted(range(len(similarities)), key=lambda i: similarities[i], reverse=True)[:top]\n",
    "    return top_5_idx\n",
    "\n",
    "def rank_thutucsidx(thutucs_idx):\n",
    "    count_dict = {}\n",
    "    for idx in thutucs_idx:\n",
    "        count_dict[idx] = count_dict.get(idx, 0) + 1\n",
    "    sorted_counts = sorted(count_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    return [{\"thutuc_idx\": e[0], \"count\": e[1]} for e in sorted_counts]\n",
    "\n",
    "for text in test_questions:\n",
    "    print(\"-\"*100)\n",
    "    print(f\"> {text}\")\n",
    "    res_exactmatch_idx = retrieve_idx_exactmatch(text=text, thutucs=thutucs, top=3)\n",
    "    res_keywordmatch_idx = retrieve_idx_keywordmatch(text=text, thutucs=thutucs, top=3)\n",
    "    res_semantic_idx_1 = retrieve_idx_semantic(text=text, pre_embs=embs_e5, emb_model=model_e5, top=3)\n",
    "    res_semantic_idx_2 = retrieve_idx_semantic(text=text, pre_embs=embs_mpnet, emb_model=model_mpnet, top=3)\n",
    "    \n",
    "    thutucs_idx = res_exactmatch_idx + res_keywordmatch_idx + res_semantic_idx_1 + res_semantic_idx_2\n",
    "\n",
    "    rank_thutucs_idx = rank_thutucsidx(thutucs_idx)\n",
    "\n",
    "    for e in rank_thutucs_idx:\n",
    "        print(f\"{thutucs[e['thutuc_idx']]['Tên thủ tục']} (score={e['count']})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
